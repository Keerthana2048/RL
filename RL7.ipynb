{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhbBH/kydaI1qaVpu5E7c9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keerthana2048/RL/blob/main/RL7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0paI5puOhQ8",
        "outputId": "f88eaa24-0c7b-43a9-e662-c2577abdf3be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class TicTacToeEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(TicTacToeEnv, self).__init__()\n",
        "        self.observation_space = spaces.Box(low=0, high=2, shape=(9,), dtype=np.int32)\n",
        "        self.action_space = spaces.Discrete(9) #specifies that there are 9 possible discrete actions (indexed as integers 0, 1, 2, …, 8)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros(9, dtype=np.int32)\n",
        "        self.current_player = 1  # 1 = X (agent), 2 = O (opponent)\n",
        "        return self.board\n",
        "\n",
        "    def step(self, action):\n",
        "        # --- Agent (X) move ---\n",
        "        if self.board[action] != 0:\n",
        "            return self.board, -10, True, {}  # illegal move\n",
        "\n",
        "        self.board[action] = 1  # agent always plays \"X\"\n",
        "        done, reward = self.check_game_over(player=1)\n",
        "        if done:\n",
        "            return self.board, reward, done, {}\n",
        "\n",
        "        # --- Opponent (O) move (random) ---\n",
        "        available = np.where(self.board == 0)[0] # returns a list of indices where the board is empty\n",
        "        if len(available) > 0:\n",
        "            opp_action = np.random.choice(available)\n",
        "            self.board[opp_action] = 2\n",
        "            done, reward = self.check_game_over(player=2)\n",
        "            if done:\n",
        "                return self.board, -1, True, {}  # agent loses → -1\n",
        "\n",
        "        return self.board, 0, False, {}\n",
        "\n",
        "    def check_game_over(self, player):\n",
        "        b = self.board.reshape(3, 3)\n",
        "        # rows & cols\n",
        "        for i in range(3):\n",
        "            if np.all(b[i] == player): return True, 1 if player == 1 else -1\n",
        "            if np.all(b[:, i] == player): return True, 1 if player == 1 else -1\n",
        "        # diagonals\n",
        "        if np.all(np.diag(b) == player): return True, 1 if player == 1 else -1\n",
        "        if np.all(np.diag(np.fliplr(b)) == player): return True, 1 if player == 1 else -1\n",
        "\n",
        "        if 0 not in self.board:  # draw\n",
        "            return True, 0\n",
        "        return False, 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToeEnv()\n",
        "obs = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample()  # random action\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    print(\"Board:\", obs.reshape(3,3), \"Reward:\", reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaLN1nfCOiXs",
        "outputId": "6b8b9afb-dd2a-4bac-e9d4-f75ea5e9baf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board: [[0 0 0]\n",
            " [0 2 0]\n",
            " [0 0 1]] Reward: 0\n",
            "Board: [[0 0 0]\n",
            " [0 2 0]\n",
            " [0 0 1]] Reward: -10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "class TicTacToeEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(TicTacToeEnv, self).__init__()\n",
        "        self.observation_space = spaces.Box(low=0, high=2, shape=(9,), dtype=np.int32)\n",
        "        self.action_space = spaces.Discrete(9)\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros(9, dtype=np.int32)\n",
        "        self.current_player = 1\n",
        "        return tuple(self.board)\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.board[action] != 0:\n",
        "            return tuple(self.board), -10, True, {}  # illegal move\n",
        "\n",
        "        self.board[action] = 1\n",
        "        if self.check_win(1): return tuple(self.board), 1, True, {}\n",
        "        if 0 not in self.board: return tuple(self.board), 0, True, {}\n",
        "\n",
        "        # Opponent random move\n",
        "        opp_moves = np.where(self.board == 0)[0] # returns a list of indices where the board is empty\n",
        "        if len(opp_moves) > 0:\n",
        "            opp_action = np.random.choice(opp_moves)\n",
        "            self.board[opp_action] = 2\n",
        "            if self.check_win(2): return tuple(self.board), -1, True, {}\n",
        "\n",
        "        return tuple(self.board), 0, False, {}\n",
        "\n",
        "    def check_win(self, player):\n",
        "        b = self.board.reshape(3,3)\n",
        "        return any([\n",
        "            np.all(b[i,:]==player) for i in range(3)\n",
        "        ]) or any([\n",
        "            np.all(b[:,j]==player) for j in range(3)\n",
        "        ]) or np.all(np.diag(b)==player) or np.all(np.diag(np.fliplr(b))==player)\n",
        "\n",
        "    # Function for planning (Value Iteration) ---\n",
        "    def get_transitions(self, state, action):\n",
        "        \"\"\"Return list of (prob, next_state, reward, done) for given (s,a).\"\"\"\n",
        "        board = np.array(state, dtype=np.int32)\n",
        "        if board[action] != 0:\n",
        "            return [(1.0, tuple(board), -10, True)]\n",
        "\n",
        "        # Apply X move\n",
        "        board[action] = 1\n",
        "        if self.check_static(board, 1):\n",
        "            return [(1.0, tuple(board), 1, True)]\n",
        "        if 0 not in board:\n",
        "            return [(1.0, tuple(board), 0, True)]\n",
        "\n",
        "        # Opponent (random)\n",
        "        opp_moves = np.where(board == 0)[0]\n",
        "        transitions = []\n",
        "        for opp_action in opp_moves:\n",
        "            new_board = board.copy()\n",
        "            new_board[opp_action] = 2\n",
        "            if self.check_static(new_board, 2):\n",
        "                transitions.append((1/len(opp_moves), tuple(new_board), -1, True))\n",
        "            else:\n",
        "                transitions.append((1/len(opp_moves), tuple(new_board), 0, False))\n",
        "        return transitions\n",
        "\n",
        "    def check_static(self, board, player):\n",
        "        b = board.reshape(3,3)\n",
        "        return any([\n",
        "            np.all(b[i,:]==player) for i in range(3)\n",
        "        ]) or any([\n",
        "            np.all(b[:,j]==player) for j in range(3)\n",
        "        ]) or np.all(np.diag(b)==player) or np.all(np.diag(np.fliplr(b))==player)"
      ],
      "metadata": {
        "id": "cbRev_6TOnxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmWq3cerOs_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}